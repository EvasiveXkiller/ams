{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD:  c:\\Coding Related\\Hackathon\\University Malaya Hackathon\n",
      "GPU Avaialble: 1\n",
      "LogisticRegressionModel(\n",
      "  (fc1): Linear(in_features=6, out_features=300, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc4): Linear(in_features=30, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from math import ceil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import os\n",
    "from sys import path as sysPath\n",
    "\n",
    "# Set your CWD path to folder containing DL Model Architecture.\n",
    "os.chdir(sysPath[0])\n",
    "print(\"CWD: \", os.getcwd())\n",
    "\n",
    "# NETWORK ARCHITECTURE TO IMPORT [inside myModel folder following the example on top]\n",
    "import LRM\n",
    "import importlib\n",
    "\n",
    "# Reload Deep Learning model if there's any changes to its architecture\n",
    "importlib.reload(LRM)\n",
    "\n",
    "print(\"GPU Avaialble:\", torch.cuda.device_count())\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NeuralNetwork = LRM.LogisticRegressionModel().to(device)\n",
    "print(NeuralNetwork)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 1218\n",
      "tensor([[-1.0584,  1.1092,  0.3351, -1.4101,  0.6226,  0.4015],\n",
      "        [-0.8606,  1.4367,  0.3428, -1.3419,  0.5178, -0.0948],\n",
      "        [-0.9950,  0.8353,  0.0278, -1.4042,  1.0507,  0.4854],\n",
      "        ...,\n",
      "        [-0.9996,  1.2988,  0.4994, -1.3577,  0.4594,  0.0997],\n",
      "        [-1.0942,  1.1621,  0.2859, -1.3198,  0.7678,  0.1982],\n",
      "        [-0.7916,  1.2582,  0.0083, -1.4415,  0.8333,  0.1333]])\n",
      "train len: 913\n",
      "test len: 305\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Maternal_Health_Risk_Data_Set_1.csv\")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 42)\n",
    "x, y  = smote.fit_resample(dataset[[\"Age\", \"SystolicBP\", \"DiastolicBP\", \"BS\", \"BodyTemp\", \"HeartRate\", \"RiskLevel\"]], dataset[\"RiskLevel\"])\n",
    "\n",
    "# Dataset x is Panda type\n",
    "dataset = x.to_numpy()\n",
    "np.random.shuffle(dataset)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "dataset_row_numbers = dataset.shape[0]\n",
    "print(\"Data rows:\", dataset_row_numbers)\n",
    "\n",
    "y_all = []\n",
    "x_all = []\n",
    "\n",
    "for row in dataset:\n",
    "        y_all.append(np.eye(LRM.num_classes)[int(row[6])])\n",
    "y_all = torch.Tensor(np.array(y_all))\n",
    "\n",
    "# Normalize data\n",
    "for row in dataset:\n",
    "        x = row[0:6].tolist() \n",
    "        dev = statistics.stdev(x)\n",
    "        mean = sum(x) / len(x)   \n",
    "        x = [(X - mean) / dev for X in x]    \n",
    "\n",
    "        x_all.append(x)\n",
    "x_all = torch.Tensor(np.array(x_all))\n",
    "print(x_all)\n",
    "\n",
    "VAL_PCT = 0.25\n",
    "val_size = ceil(len(x_all)*VAL_PCT)\n",
    "\n",
    "train_X = x_all[:-val_size]\n",
    "train_y = y_all[:-val_size]\n",
    "\n",
    "test_X = x_all[-val_size:]\n",
    "test_y = y_all[-val_size:]\n",
    "\n",
    "print(\"train len:\", len(train_X))\n",
    "print(\"test len:\", len(test_X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "TEST_BATCH_STEP = 10\n",
    "learning_rate = 0.00005\n",
    "\n",
    "# optimizer = torch.optim.SGD(NeuralNetwork.parameters(), lr=learning_rate)  \n",
    "# optimizer = optim.Adam(NeuralNetwork.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.RMSprop(NeuralNetwork.parameters(), lr=learning_rate, alpha=0.9, eps=1e-07)\n",
    "\n",
    "# Choose loss function\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n",
    "def fwd_pass(X,y, train=False):\n",
    "    if not train:\n",
    "        NeuralNetwork.zero_grad()\n",
    "    \n",
    "    outputs = NeuralNetwork(X)\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    matches = [torch.argmax(i)==torch.argmax(j) for i,j in zip(outputs, y)]\n",
    "    acc = matches.count(True) / len(matches)   \n",
    "\n",
    "    loss = loss_function(outputs, y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return acc, loss\n",
    "\n",
    "def test(size):\n",
    "    random_start = np.random.randint(len(test_X)-size)\n",
    "    X, y = test_X[random_start:random_start+size], test_y[random_start:random_start+size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(X.to(device), y.to(device))\n",
    "    \n",
    "    return val_acc, val_loss\n",
    "\n",
    "\n",
    "def trainModel():    \n",
    "    counterNow = 0\n",
    "\n",
    "    with open(\"currentModelLog.log\", \"w\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "\n",
    "            print(f\"EPOCH {epoch + 1}\", end=\": \")\n",
    "            \n",
    "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "                counterNow += 1\n",
    "\n",
    "                batch_X = train_X[i:i+BATCH_SIZE].to(device)\n",
    "                batch_y = train_y[i:i+BATCH_SIZE].to(device)\n",
    "                \n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "                \n",
    "                if i % TEST_BATCH_STEP == 0:\n",
    "                    val_acc, val_loss = test(TEST_BATCH_SIZE)\n",
    "                    f.write(f\"{round(time.time(),3)}, { round(float(acc),2) }, {round(float(loss),2)}, {round(float(val_acc),2)}, {round(float(val_loss),2)}\\n\")\n",
    "\n",
    "    return counterNow\n",
    "\n",
    "counter_runs = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"ggplot\")\n",
    "\n",
    "def createGraph():\n",
    "    contents = open(\"currentModelLog.log\", \"r\").read().split(\"\\n\")\n",
    "    \n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "\n",
    "    for c in contents:\n",
    "        if c:\n",
    "            timestamp, acc, loss, val_acc, val_loss = c.split(\",\")       \n",
    "            times.append(float(timestamp)) \n",
    "            accuracies.append(float(acc)) \n",
    "            losses.append(float(loss)) \n",
    "            val_accs.append(float(val_acc)) \n",
    "            val_losses.append(float(val_loss)) \n",
    "    \n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (1,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n",
    "    \n",
    "    ax1.plot(times, accuracies, label=\"T Accuracy\")\n",
    "    ax1.plot(times, val_accs, label=\"V Accuracy\")\n",
    "    ax1.legend(loc=2)\n",
    "    \n",
    "    ax2.plot(times, losses, label=\"T Loss\")\n",
    "    ax2.plot(times, val_losses, label=\"V Loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Last Test Loss:\", val_losses[-1])\n",
    "    print(\"Last Test Acc:\", val_accs[-1])\n",
    "    \n",
    "createGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "TEST_NUM = random.randint(0, len(test_X))\n",
    "\n",
    "print(test_X[TEST_NUM].shape)\n",
    "print(torch.tensor([test_X[TEST_NUM].tolist()]).shape)\n",
    "\n",
    "prediction = NeuralNetwork(torch.tensor([test_X[TEST_NUM].tolist()]).to(device))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "answer = torch.argmax(prediction[0]).item()\n",
    "prob = prediction[0][answer].item()\n",
    "\n",
    "print(\"ANSWER INDEX:\", answer)\n",
    "print(\"ANSWER PROBABILITY:\", prob)\n",
    "print(\"CORRECT ANSWER:\", test_y[TEST_NUM])\n",
    "\n",
    "if(test_y[TEST_NUM][answer] == 1):\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(NeuralNetwork.state_dict(), \"model.pt\")\n",
    "\n",
    "pytorch_model = LRM.LogisticRegressionModel()\n",
    "pytorch_model.load_state_dict(torch.load(\"model.pt\"))\n",
    "pytorch_model.eval()\n",
    "dummy_input = torch.tensor([torch.zeros(6).tolist()])\n",
    "torch.onnx.export(pytorch_model, dummy_input, \"onnx_model.onnx\", verbose=True)\n",
    "\n",
    "print(dummy_input.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
